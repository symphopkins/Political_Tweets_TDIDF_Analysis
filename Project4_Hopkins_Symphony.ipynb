{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0839989",
   "metadata": {},
   "source": [
    "# DSCI 614: Project 4\n",
    "\n",
    "### Symphony Hopkins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f5aeb",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We are acting as a data scientist working for a Political Consulting Firm. We were given a dataset containing in Twitter_Data.csv. This dataset has the following two columns:\n",
    "+ clean_text: Tweets made by the people extracted from Twitter Mainly Focused on tweets Made by People on Modi(2019 Indian Prime Minister candidate) and Other Prime Ministerial Candidates.\n",
    "+ category: It describes the actual sentiment of the respective tweet with three values of -1, 0, and 1.\n",
    "\n",
    "We were asked to perform the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e76fb",
   "metadata": {},
   "source": [
    "## 1. Load the dataset of Twitter_Data.csv into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266084ab",
   "metadata": {},
   "source": [
    "Let's load the dataset into memory using the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b6f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "220c7a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieving data from csv file and storing it into a dataframe\n",
    "twitter_data=pd.read_csv('/Users/symphonyhopkins/Documents/Maryville_University/DSCI_614/Week_4/Twitter_Data.csv')\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc020c0b",
   "metadata": {},
   "source": [
    "Let's look at the shape of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a5642f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162980, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying shape\n",
    "twitter_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f42fc",
   "metadata": {},
   "source": [
    "As we can see, we have a large dataset, with approximately 163,000 rows and 2 columns. We will also check to see if there are missing values. If there are missing values, we will need to address them, otherwise, it will create errors later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51730270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    4\n",
       "category      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "twitter_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d38d633",
   "metadata": {},
   "source": [
    "We can deal with missing values in multiple ways. For this case, we will simply drop the rows with missing values since it is only a small amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61c7d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162969, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping rows with missing values\n",
    "twitter_data = twitter_data.dropna()\n",
    "\n",
    "# displaying new shape\n",
    "twitter_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d02b13",
   "metadata": {},
   "source": [
    "## 2. Convert the column of the clean_text to a matrix of token counts using CountVectorizer and unigrams and bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b3496",
   "metadata": {},
   "source": [
    "In order to perform text feature extraction, we need to create numerical representations for the texts, so we are going to convert the clean_text column to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5873d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e80a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the feature matrix for the texts = (162969, 1199719)\n",
      "The first row of the feature matrix =   (0, 1145433)\t1\n",
      "  (0, 666550)\t1\n",
      "  (0, 831874)\t1\n",
      "  (0, 658436)\t1\n",
      "  (0, 435496)\t1\n",
      "  (0, 644085)\t1\n",
      "  (0, 435144)\t1\n",
      "  (0, 357405)\t1\n",
      "  (0, 480827)\t1\n",
      "  (0, 134189)\t1\n",
      "  (0, 1029267)\t2\n",
      "  (0, 299531)\t1\n",
      "  (0, 554527)\t1\n",
      "  (0, 867035)\t1\n",
      "  (0, 976961)\t2\n",
      "  (0, 1155015)\t1\n",
      "  (0, 308537)\t1\n",
      "  (0, 1006645)\t1\n",
      "  (0, 1183127)\t1\n",
      "  (0, 419831)\t1\n",
      "  (0, 562991)\t1\n",
      "  (0, 940181)\t2\n",
      "  (0, 66073)\t3\n",
      "  (0, 728511)\t1\n",
      "  (0, 175799)\t1\n",
      "  :\t:\n",
      "  (0, 357481)\t1\n",
      "  (0, 481025)\t1\n",
      "  (0, 134240)\t1\n",
      "  (0, 1032232)\t1\n",
      "  (0, 299593)\t1\n",
      "  (0, 555042)\t1\n",
      "  (0, 867040)\t1\n",
      "  (0, 1038732)\t1\n",
      "  (0, 977637)\t1\n",
      "  (0, 1155436)\t1\n",
      "  (0, 309052)\t1\n",
      "  (0, 1007443)\t1\n",
      "  (0, 1183655)\t1\n",
      "  (0, 420540)\t1\n",
      "  (0, 563130)\t1\n",
      "  (0, 977513)\t1\n",
      "  (0, 940255)\t1\n",
      "  (0, 72487)\t1\n",
      "  (0, 729190)\t1\n",
      "  (0, 175815)\t1\n",
      "  (0, 74556)\t1\n",
      "  (0, 940627)\t1\n",
      "  (0, 356855)\t1\n",
      "  (0, 838910)\t1\n",
      "  (0, 75386)\t1.\n",
      "There are 60/1199719 non-zeros\n"
     ]
    }
   ],
   "source": [
    "# creating a vectorizer object using 1-grams and 2-grams\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# encoding the corpus\n",
    "# extracting token counts out of raw text documents using the vocabulary\n",
    "token_count_matrix = vectorizer.fit_transform(twitter_data['clean_text'])\n",
    "\n",
    "# summarizing the numerical features from texts\n",
    "print(f'The size of the feature matrix for the texts = {token_count_matrix.get_shape()}')\n",
    "print(f'The first row of the feature matrix = {token_count_matrix[0, ]}.')\n",
    "print(f'There are {token_count_matrix[0, ].count_nonzero()}/{token_count_matrix.get_shape()[1]} non-zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a85f40e",
   "metadata": {},
   "source": [
    "When we account for 1-grams and 2-grams, we can see that we have approximately 120,000 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a571049",
   "metadata": {},
   "source": [
    "## 3. Perform the tf-idf anlysis on the column of the clean_text using CountVectorizer and TfidfTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ee11c",
   "metadata": {},
   "source": [
    "We will now use tf-idf analysis to determine how important each word is to the documents using CountVectorizer and TfidfTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f080893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing library\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b582156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the count matrix for the texts = (162969, 106924)\n",
      "The sparse count matrix is as follows:\n",
      "  (0, 103779)\t1\n",
      "  (0, 62480)\t1\n",
      "  (0, 76936)\t1\n",
      "  (0, 61636)\t1\n",
      "  (0, 40526)\t1\n",
      "  (0, 60316)\t1\n",
      "  (0, 40498)\t1\n",
      "  (0, 34701)\t1\n",
      "  (0, 43979)\t1\n",
      "  (0, 13684)\t1\n",
      "  (0, 95481)\t2\n",
      "  (0, 29341)\t1\n",
      "  (0, 51356)\t1\n",
      "  (0, 80437)\t1\n",
      "  (0, 91103)\t2\n",
      "  (0, 103993)\t1\n",
      "  (0, 30477)\t1\n",
      "  (0, 93827)\t1\n",
      "  (0, 105520)\t1\n",
      "  (0, 39395)\t1\n",
      "  (0, 51984)\t1\n",
      "  (0, 87791)\t2\n",
      "  (0, 8389)\t3\n",
      "  (0, 67997)\t1\n",
      "  (0, 17907)\t1\n",
      "  :\t:\n",
      "  (162968, 65872)\t1\n",
      "  (162968, 56602)\t1\n",
      "  (162968, 95374)\t1\n",
      "  (162968, 63946)\t1\n",
      "  (162968, 5841)\t1\n",
      "  (162968, 5191)\t1\n",
      "  (162968, 74811)\t1\n",
      "  (162968, 17962)\t1\n",
      "  (162968, 69382)\t1\n",
      "  (162968, 43150)\t1\n",
      "  (162968, 103787)\t1\n",
      "  (162968, 47230)\t1\n",
      "  (162968, 82980)\t2\n",
      "  (162968, 34101)\t1\n",
      "  (162968, 34124)\t1\n",
      "  (162968, 89692)\t1\n",
      "  (162968, 77338)\t1\n",
      "  (162968, 10864)\t2\n",
      "  (162968, 44214)\t1\n",
      "  (162968, 25873)\t1\n",
      "  (162968, 56815)\t1\n",
      "  (162968, 58706)\t1\n",
      "  (162968, 29767)\t1\n",
      "  (162968, 58705)\t1\n",
      "  (162968, 41682)\t1\n",
      "The size of the tf_idf matrix for the texts = (162969, 106924)\n",
      "The sparse tf_idf matrix is as follows:\n",
      "  (0, 105520)\t0.1202870832218194\n",
      "  (0, 103993)\t0.10858917152548611\n",
      "  (0, 103779)\t0.11668516757081547\n",
      "  (0, 95481)\t0.11033764463078544\n",
      "  (0, 94773)\t0.23660485539606374\n",
      "  (0, 93827)\t0.13399884686280536\n",
      "  (0, 91103)\t0.3105065912100438\n",
      "  (0, 87791)\t0.2387412625319213\n",
      "  (0, 80437)\t0.3147740451523205\n",
      "  (0, 77542)\t0.264444475409766\n",
      "  (0, 76936)\t0.16616000283439675\n",
      "  (0, 67997)\t0.08143326134816188\n",
      "  (0, 62480)\t0.0333688896457597\n",
      "  (0, 61636)\t0.1889101027139982\n",
      "  (0, 60316)\t0.2168692945303043\n",
      "  (0, 51984)\t0.20306582436747228\n",
      "  (0, 51356)\t0.15495484008618038\n",
      "  (0, 43979)\t0.11613310705621374\n",
      "  (0, 40526)\t0.12555123559382841\n",
      "  (0, 40498)\t0.19217208728463125\n",
      "  (0, 39395)\t0.12597723786710185\n",
      "  (0, 34701)\t0.20196149331154298\n",
      "  (0, 34636)\t0.2517654038938211\n",
      "  (0, 30477)\t0.1452392676417048\n",
      "  (0, 29341)\t0.20379905962908565\n",
      "  :\t:\n",
      "  (162968, 82980)\t0.34251482656053117\n",
      "  (162968, 77338)\t0.15060798979573622\n",
      "  (162968, 74811)\t0.15343350913853246\n",
      "  (162968, 69382)\t0.1056099111348009\n",
      "  (162968, 65872)\t0.10545001234393728\n",
      "  (162968, 63946)\t0.11822149299480865\n",
      "  (162968, 62480)\t0.033547020635827554\n",
      "  (162968, 58706)\t0.2720694809364135\n",
      "  (162968, 58705)\t0.2631914858841437\n",
      "  (162968, 56815)\t0.18852664518611578\n",
      "  (162968, 56602)\t0.10462614089305383\n",
      "  (162968, 47230)\t0.12161758129405911\n",
      "  (162968, 44214)\t0.22911272676340105\n",
      "  (162968, 43150)\t0.09222074968263473\n",
      "  (162968, 41682)\t0.34070776595153984\n",
      "  (162968, 37265)\t0.06756382755954866\n",
      "  (162968, 34124)\t0.16072166193644719\n",
      "  (162968, 34101)\t0.12109308875411293\n",
      "  (162968, 29767)\t0.25797264287561616\n",
      "  (162968, 25873)\t0.20296193314712377\n",
      "  (162968, 17962)\t0.09300912393447665\n",
      "  (162968, 10864)\t0.3364420788367229\n",
      "  (162968, 9779)\t0.08443257082857562\n",
      "  (162968, 5841)\t0.1755037950979183\n",
      "  (162968, 5191)\t0.11241538767448883\n"
     ]
    }
   ],
   "source": [
    "# creating a vectorizer object using the default parameters\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# extracting token counts out of raw text documents using the vocabulary\n",
    "token_count_matrix = vectorizer.fit_transform(twitter_data['clean_text'])\n",
    "\n",
    "# summarizing token count matrix\n",
    "print(f'The size of the count matrix for the texts = {token_count_matrix.get_shape()}')\n",
    "print(f'The sparse count matrix is as follows:')\n",
    "print(token_count_matrix)\n",
    "\n",
    "# creating a tf_idf object using the default parameters\n",
    "tf_idf_transformer=TfidfTransformer(use_idf=True, smooth_idf=True, sublinear_tf=False) \n",
    "\n",
    "# fitting to the token_count_matrix, then transforming it to a normalized tf-idf representation\n",
    "tf_idf_matrix_1 = tf_idf_transformer.fit_transform(token_count_matrix)\n",
    "\n",
    "# summarizing the tf_idf_matrix\n",
    "print(f'The size of the tf_idf matrix for the texts = {tf_idf_matrix_1.get_shape()}')\n",
    "print(f'The sparse tf_idf matrix is as follows:')\n",
    "print(tf_idf_matrix_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15ff89",
   "metadata": {},
   "source": [
    "## 4. Perform the tf-idf analysis on the column of the clean_text using Tfidfvectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110850c",
   "metadata": {},
   "source": [
    "We will do the same thing using only the Tfidfvectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4fea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "354fdccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the tf_idf matrix for the texts = (162969, 106924)\n",
      "The sparse tf_idf matrix is as follows:\n",
      "  (0, 94773)\t0.23660485539606377\n",
      "  (0, 77542)\t0.26444447540976607\n",
      "  (0, 34636)\t0.2517654038938212\n",
      "  (0, 17907)\t0.18097710894277283\n",
      "  (0, 67997)\t0.0814332613481619\n",
      "  (0, 8389)\t0.18586937299338827\n",
      "  (0, 87791)\t0.23874126253192132\n",
      "  (0, 51984)\t0.20306582436747234\n",
      "  (0, 39395)\t0.12597723786710188\n",
      "  (0, 105520)\t0.12028708322181941\n",
      "  (0, 93827)\t0.1339988468628054\n",
      "  (0, 30477)\t0.14523926764170483\n",
      "  (0, 103993)\t0.10858917152548613\n",
      "  (0, 91103)\t0.31050659121004387\n",
      "  (0, 80437)\t0.31477404515232055\n",
      "  (0, 51356)\t0.1549548400861804\n",
      "  (0, 29341)\t0.2037990596290857\n",
      "  (0, 95481)\t0.11033764463078546\n",
      "  (0, 13684)\t0.22828354889246916\n",
      "  (0, 43979)\t0.11613310705621377\n",
      "  (0, 34701)\t0.201961493311543\n",
      "  (0, 40498)\t0.19217208728463128\n",
      "  (0, 60316)\t0.21686929453030435\n",
      "  (0, 40526)\t0.12555123559382844\n",
      "  (0, 61636)\t0.18891010271399822\n",
      "  :\t:\n",
      "  (162968, 10864)\t0.33644207883672295\n",
      "  (162968, 77338)\t0.15060798979573625\n",
      "  (162968, 89692)\t0.1773135448853426\n",
      "  (162968, 34124)\t0.1607216619364472\n",
      "  (162968, 34101)\t0.12109308875411295\n",
      "  (162968, 82980)\t0.3425148265605312\n",
      "  (162968, 47230)\t0.12161758129405914\n",
      "  (162968, 103787)\t0.13830450920478798\n",
      "  (162968, 43150)\t0.09222074968263476\n",
      "  (162968, 69382)\t0.10560991113480092\n",
      "  (162968, 17962)\t0.09300912393447666\n",
      "  (162968, 74811)\t0.1534335091385325\n",
      "  (162968, 5191)\t0.11241538767448886\n",
      "  (162968, 5841)\t0.17550379509791833\n",
      "  (162968, 63946)\t0.11822149299480868\n",
      "  (162968, 95374)\t0.08325389879560323\n",
      "  (162968, 56602)\t0.10462614089305386\n",
      "  (162968, 65872)\t0.1054500123439373\n",
      "  (162968, 9779)\t0.08443257082857564\n",
      "  (162968, 105956)\t0.08074391363076924\n",
      "  (162968, 37265)\t0.06756382755954868\n",
      "  (162968, 104110)\t0.0835204286733823\n",
      "  (162968, 93827)\t0.1347141642591292\n",
      "  (162968, 95481)\t0.05546332647912858\n",
      "  (162968, 62480)\t0.03354702063582756\n"
     ]
    }
   ],
   "source": [
    "# creating a TfidfVectorizer Object using the default parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "# fitting to the corpus, then converingt a collection of raw documents to a matrix of TF-IDF features.\n",
    "tf_idf_matrix_2 = tfidf_vectorizer.fit_transform(twitter_data['clean_text'])\n",
    "\n",
    "# summarizing the tf_idf_matrix\n",
    "print(f'The size of the tf_idf matrix for the texts = {tf_idf_matrix_2.get_shape()}')\n",
    "print(f'The sparse tf_idf matrix is as follows:')\n",
    "print(tf_idf_matrix_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452ac43",
   "metadata": {},
   "source": [
    "## 5. Perform the tf-idf analysis on the column of the clean_text using HashingVectorizer and TfidfTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf09104",
   "metadata": {},
   "source": [
    "Once again, we will perform tf-idf analysis but only use HashingVectorizer and TfidfTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "284ad193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library\n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e241a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the count matrix for the texts = (162969, 1048576)\n",
      "The sparse count matrix is as follows:\n",
      "  (0, 160541)\t0.14907119849998599\n",
      "  (0, 168557)\t0.14907119849998599\n",
      "  (0, 180525)\t-0.4472135954999579\n",
      "  (0, 232512)\t0.14907119849998599\n",
      "  (0, 263274)\t0.14907119849998599\n",
      "  (0, 277794)\t-0.14907119849998599\n",
      "  (0, 286878)\t-0.29814239699997197\n",
      "  (0, 288398)\t0.14907119849998599\n",
      "  (0, 360502)\t0.29814239699997197\n",
      "  (0, 387101)\t-0.14907119849998599\n",
      "  (0, 433698)\t0.14907119849998599\n",
      "  (0, 434864)\t0.14907119849998599\n",
      "  (0, 449993)\t-0.14907119849998599\n",
      "  (0, 465141)\t-0.14907119849998599\n",
      "  (0, 482215)\t-0.14907119849998599\n",
      "  (0, 484920)\t-0.14907119849998599\n",
      "  (0, 490370)\t0.29814239699997197\n",
      "  (0, 522187)\t0.14907119849998599\n",
      "  (0, 614924)\t0.14907119849998599\n",
      "  (0, 646934)\t0.14907119849998599\n",
      "  (0, 747378)\t-0.14907119849998599\n",
      "  (0, 748718)\t0.14907119849998599\n",
      "  (0, 808196)\t-0.14907119849998599\n",
      "  (0, 839641)\t-0.14907119849998599\n",
      "  (0, 865698)\t0.14907119849998599\n",
      "  :\t:\n",
      "  (162968, 257965)\t0.16222142113076254\n",
      "  (162968, 286878)\t-0.16222142113076254\n",
      "  (162968, 338809)\t0.16222142113076254\n",
      "  (162968, 372702)\t0.16222142113076254\n",
      "  (162968, 408714)\t-0.16222142113076254\n",
      "  (162968, 413699)\t-0.16222142113076254\n",
      "  (162968, 433698)\t0.16222142113076254\n",
      "  (162968, 449993)\t-0.16222142113076254\n",
      "  (162968, 487855)\t-0.16222142113076254\n",
      "  (162968, 507870)\t-0.16222142113076254\n",
      "  (162968, 512176)\t0.16222142113076254\n",
      "  (162968, 528700)\t-0.16222142113076254\n",
      "  (162968, 642085)\t0.16222142113076254\n",
      "  (162968, 675997)\t0.16222142113076254\n",
      "  (162968, 707819)\t0.16222142113076254\n",
      "  (162968, 730607)\t-0.16222142113076254\n",
      "  (162968, 731192)\t0.3244428422615251\n",
      "  (162968, 800174)\t-0.16222142113076254\n",
      "  (162968, 814105)\t0.16222142113076254\n",
      "  (162968, 832412)\t0.16222142113076254\n",
      "  (162968, 865514)\t0.16222142113076254\n",
      "  (162968, 865966)\t0.16222142113076254\n",
      "  (162968, 975831)\t-0.16222142113076254\n",
      "  (162968, 994433)\t0.16222142113076254\n",
      "  (162968, 1031365)\t0.16222142113076254\n",
      "The size of the tf_idf matrix for the texts = (162969, 1048576)\n",
      "The sparse tf_idf matrix is as follows:\n",
      "  (0, 1011271)\t0.20372786215764271\n",
      "  (0, 926068)\t0.08143774314362087\n",
      "  (0, 913601)\t0.2019726085498207\n",
      "  (0, 865698)\t0.12597880634966283\n",
      "  (0, 839641)\t-0.2644590294879084\n",
      "  (0, 808196)\t-0.1161394986070767\n",
      "  (0, 748718)\t0.1255581454848022\n",
      "  (0, 747378)\t-0.23661787728108877\n",
      "  (0, 646934)\t0.1085951478851183\n",
      "  (0, 614924)\t0.15496336824638357\n",
      "  (0, 522187)\t0.18098706927558536\n",
      "  (0, 490370)\t0.23875440199715425\n",
      "  (0, 484920)\t-0.12029370339267384\n",
      "  (0, 482215)\t-0.14524726109154837\n",
      "  (0, 465141)\t-0.1661691476866824\n",
      "  (0, 449993)\t-0.13400622168009055\n",
      "  (0, 434864)\t0.2030770003841817\n",
      "  (0, 433698)\t0.033370726150102156\n",
      "  (0, 387101)\t-0.18892049965041563\n",
      "  (0, 360502)\t0.3104936841079061\n",
      "  (0, 288398)\t0.22829611280254533\n",
      "  (0, 286878)\t-0.11034371722012394\n",
      "  (0, 277794)\t-0.2517792601612138\n",
      "  (0, 263274)\t0.21675091439391558\n",
      "  (0, 232512)\t0.11669158950511473\n",
      "  :\t:\n",
      "  (162968, 800174)\t-0.25797319266567015\n",
      "  (162968, 731192)\t0.33644279586046083\n",
      "  (162968, 730607)\t-0.10545023707849568\n",
      "  (162968, 707819)\t0.3407084920662896\n",
      "  (162968, 675997)\t0.0835206066717176\n",
      "  (162968, 642085)\t0.17550416913076108\n",
      "  (162968, 528700)\t-0.10561013621013485\n",
      "  (162968, 512176)\t0.0844327507708639\n",
      "  (162968, 507870)\t-0.22911321504734083\n",
      "  (162968, 487855)\t-0.08325407622591133\n",
      "  (162968, 449993)\t-0.1347144513613072\n",
      "  (162968, 433698)\t0.03354709213107635\n",
      "  (162968, 413699)\t-0.27207006076958085\n",
      "  (162968, 408714)\t-0.11821772719938424\n",
      "  (162968, 372702)\t0.0930093221550736\n",
      "  (162968, 338809)\t0.11240578785536466\n",
      "  (162968, 286878)\t-0.05546344468230281\n",
      "  (162968, 257965)\t0.18852704697319397\n",
      "  (162968, 213357)\t0.20296236569861814\n",
      "  (162968, 194734)\t0.3425155565264798\n",
      "  (162968, 189643)\t-0.06756397155125254\n",
      "  (162968, 181881)\t-0.1773139227751154\n",
      "  (162968, 176851)\t-0.26319204679657077\n",
      "  (162968, 77761)\t-0.1216133166683147\n",
      "  (162968, 60869)\t-0.12109334682712045\n"
     ]
    }
   ],
   "source": [
    "#creating a HashingVectorizer object using the default parameters\n",
    "hash_vectorizer = HashingVectorizer()\n",
    "\n",
    "# converting a collecting of text documents to a matrix token counts using hash vectorizing\n",
    "token_count_matrix=hash_vectorizer.fit_transform(twitter_data['clean_text'])\n",
    "\n",
    "# summarizing the count matrix\n",
    "print(f'The size of the count matrix for the texts = {token_count_matrix.get_shape()}')\n",
    "print(f'The sparse count matrix is as follows:')\n",
    "print(token_count_matrix)\n",
    "\n",
    "# we will use the transformer we created in step 3 since it is already set to the default parameters\n",
    "# fitting to the count matrix, then transforming it to a normalized tf-idf representation\n",
    "tf_idf_matrix_3 = tf_idf_transformer.fit_transform(token_count_matrix)\n",
    "\n",
    "# summarizing the tf_idf_matrix\n",
    "print(f'The size of the tf_idf matrix for the texts = {tf_idf_matrix_3.get_shape()}')\n",
    "print(f'The sparse tf_idf matrix is as follows:')\n",
    "print(tf_idf_matrix_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
